<h1 align="center">üêç Python Packages</h1>

> ### See more Python AI packages [here](https://skymind.ai/wiki/python-ai)


### Index


| üêº **Dataframe** |  üìä **Visualization** | üí° **Machine Learning** | üå≥ **Gradient Boosting** | üî¶ **Deep Learning** |
|:-----------------|:----------------------|:-------------------------|:-------------------------|:---------------------|
| Pandas           | Matplotlib       ‚≠ê   | Scikit learn    ‚≠ê       | XGBoost                  | Pytorch = PT         |
| Datatable   ‚≠ê   | Seaborn               | H2O                      | LightGBM ‚≠ê              | Tensorflow = TF      |
| CuDF             | Plotly                | CuML                     | CatBoost                 | Fast.ai (PT)   ‚≠ê    |
| Dask             | Bokeh                 | Dask-ML                  |                          | Catalyst (PT)        |
|                  |                       |                          |                          | Ignite (PT)          |
|                  |                       |                          |                          | Keras (TF)           |

Others:

| üï∑Ô∏è **Web Scraping** | üî¢ **Numeric** | üçπ **Auto ML** | ‚ùì **ML visual** |
|---------------------|----------------|-----------------|------------------|
| Beautiful Soup      | Numpy          | H2O ‚≠ê          | ELI5             |
| Scrapy              | Scipy          | Auto Sklearn    | Yellowbrick      |
|                     | Statsmodels    | TPOT            | Tensorboard (DL) |
|                     |                | MLBox           |                  |


### Data Manipulation & Wrangling

- [agate](): data analysis library with human-readable code
- [arrow](): date & time manipulation & formatting
- [beautifulsoup4](): Beautiful Soup, for parsing HTML, JSON & XML data
- [engarde](): defensive data analysis
- [jsonify](): converts .csv files to .json
- [numexpr](): fast numerical array expression evaluator
- [numpy](): scientific computing library
- [pandas](): data structures & data analysis tools
- [pandas_profiling](): generates profile reports from a pandas DataFrame
- [pandasql](): queries pandas dataframes using SQL syntax
- [prettytable](): easily display tabular data as ASCII table
- [shapely](): manipulation & analysis of geometric objects
- [tabulate](): pretty-print tabular data


### Machine Learning & Statistics

- [cvxopt](): convex optimization library
- [emcee](): an MIT MCMC library
- [hdbscan](): Hierarchical Density-Based Spatial Clustering of Applications with Noise
- [keras](): high-level neural networks API
- [lifelines](): survival analysis in Python
- [lifetimes](): package for analyzing user behavior
- [prophet](): procedure for forecasting time series data
- [pymc3](): probabilistic programming & Bayesian modeling
- [gensim](): unsupervised semantic modeling from plain text
- [scikit-image](): image processing library
- [scikit-learn](): tools for data mining & analysis
- [scikits-bootstrap](): bootstrap confidence interval algorithms for scipy
- [scipy](): for mathematics, science & engineering
- [statsmodels](): estimate statistical models & perform statistical tests
- [sympy](): symbolic mathematics
- [tensorflow](): numerical computation using data flow graphs
- [xgboost](): optimized distributed gradient boosting library


### Visualization

- [folium](): build Leaflet.js maps in Python
- [gviz_api](): helper library for Google Visualization API
- [igraph](): network analysis tools
- [mapbox](): client for Mapbox web services
- [matplotlib](): 2D plotting library
- [patsy](): describe statistical models & build design matrices
- [plotly](): create interactive graphics
- [pygal](): create interactive svg charts
- [pygraphviz](): interface for Graphviz graph layout & visualizations
- [pyproj](): cartographic transformations & geodetic computations
- [seaborn](): viz library to draw statistical graphics
- [squarify](): implementation of the squarify treemap layout algorithm
- [wordcloud](): wordcloud generator in Python


### Everything Else

- [cufflinks](): bind Plotly directly to pandas dataframes
- [datascience](): library for introductory data science
- [fiona](): read & write geospatial data files
- [geopandas](): extends pandas to allow spatial operations on geometric types
- [networkx](): create, manipulate & study networks
- [nltk](): natural language toolkit
- [pysal](): geospatial analysis library
- [pyzipcode3](): query zip codes & location data
- [requests](): allows HTTP requests
- [scrapy](): scraping web pages
- [six](): Python 2 & 3 compatibility library
- [spacy](): advanced natural language processing
- [textblob](): simple API for common NLP tasks
- [ua_parser](): fast & reliable user agent parser
- [urllib3](): HTTP client for python

---



<h1 align="center">NLP Packages</h1>


| Packages                                         | Description                                                               | Type |
|:------------------------------------------------:|---------------------------------------------------------------------------|------|
| <img src="img/logo/spacy.png" height="40">       | Parse trees, execelent tokenizer (8 languages)                            | üî§ |
| <img src="img/logo/gensim.jpg" height="30">      | Semantic analysis, topic modeling and similarity detection.               | üî§ |
| <h3>NLTK</h3>                                    | Very broad NLP library. Not SotA.                                         | üî§ |
| <h3>SentencePiece</h3>                           | Unsupervised text tokenizer by Google                                     | üî§ |
| <img src="img/logo/fastai.png" height="50">      | Fast.ai NLP: ULMFiT fine-tuning                                           | üî§ |
| <img src="img/logo/pytorch.png" height="30">     | TorchText (Pytorch subpackage)                                            | üî§ |
| <img src="img/logo/fasttext.png" height="50">    | Word vector representations and sentence classification (157 languages)   | üî§ |
| <img src="img/logo/huggingface.png" height="50"> | pytorch-transformers: 8 pretrained Pytorch transformers                   | üî§ |
| <img  src="img/logo/spacy.png" height="30">+<img src="img/logo/huggingface.png" height="40"> | SpaCy + pytorch-transformers  | üî§ |
| <h3>fast-bert</h3>                               | Super easy library for BERT based models                                  | üî§ |
| <img src="img/logo/stanfordnlp.jpg" height="50"> | Pretrained models for 53 languages                                        | üî§ |
| <h3>PyText</h3>                                  |                                                                           | üî§ |
| <img src="img/logo/allennlp.png" height="20">    | An open-source NLP research library, built on PyTorch.                    | üî§ |
| <img src="img/logo/farm.png" height="40">        | Fast & easy NLP transfer learning for the industry.                       | üî§ |
| <img src="img/logo/transfernlp.jpg" height="30"> | NLP library designed for reproducible experimentation management.         | üî§ |
| <img src="img/logo/flair.png" height="40">       | A very simple framework for state-of-the-art NLP.                         | üî§ |
| <img src="img/logo/nlparchitect.png" height="30">| SotA NLP deep learning topologies and techniques.                         | üî§ |
| <img src="img/logo/finetune.png" height="30">    | Scikit-learn style model finetuning for NLP.                              | üî§ |



---

<h1 align="center">Python Parallelization ‚è©</h1>

> ### [todo](https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9797-dask-extensions-and-new-developments-with-rapids.pdf)

- CPU
  - [**Python Threading**](#threading)
  - [**Python Multiprocessing**](#multiprocessing)
  - [**PyTorch Multiprocessing**](#pytorch-multiprocessing)
  - [**Numba JIT**](#numba)
- GPU
  - [**PyTorch CUDA**](#pytorch-cuda): Numeric parallelization similar to NumPy
  - [**Numba CUDA**](#numba-cuda): Easy parallelization
  - **cuDF**: DataFrame parallelization similar to Pandas (by RAPIDS)
  - **cuML**: Machine learn. parallelization similar to Scikit-learn (by RAPIDS)
  - **cuGraph**: graph parallelization similar to NetworkX (by RAPIDS)
  - [**CuPy**](#cupy): GPU matrix library similar to NumPy
  - **PyCuda**
  - **PyOpenCL**
  - **Dask**: Distributed parallelization

  

<h1 align="center">CPU</h1>

## Threading

Due to python GIL (global interpreter lock), only a single thread can acquire that lock at a time, which means the interpreter ultimately **runs the instructions serially** ‚òπÔ∏è. This bottleneck, however, becomes irrelevant if your program has a more severe bottleneck elsewhere, for example in network, IO, or user interaction.

Threading is useful in:
- GUI programs: For example, in a text editing program, one thread can take care of recording the user inputs, another can be responsible for displaying the text, a third can do spell-checking, and so on.
- Network programs: For example web-scrapers. In this case, multiple threads can take care of scraping multiple webpages in parallel. The threads have to download the webpages from the Internet, and that will be the biggest bottleneck, so threading is a perfect solution here. Web servers, work similarly.

```python
import threading

def func(x):
    return x*x

thread1 = threading.Thread(target=func, args=(4))
thread2 = threading.Thread(target=func, args=(5))

thread1.start() # Starts the thread asynchronously
thread2.start() # Starts the thread asynchronously

thread1.join()  # Wait to terminate
thread2.join()  # Wait to terminate
```

## Multiprocessing

Multiprocessing outshines threading in cases where the program is CPU intensive and doesn‚Äôt have to do any IO or user interaction. For example, any program that just crunches numbers.

```python
import multiprocessing

def func(x):
    return x*x

process1 = multiprocessing.Process(target=func, args=(4))
process2 = multiprocessing.Process(target=func, args=(5))

process1.start() # Start the process
process2.start() # Start the process

process1.join()  # Wait to terminate
process2.join()  # Wait to terminate
```

#### Multiprocessing pool

```python
import multiprocessing

def f(x):
    return x*x

cores = 4
pool = multiprocessing.Pool(cores)
pool.map(f, [1, 2, 3])
```

## PyTorch (Multiprocessing)

PyTorch multiprocessing is a wrapper around the native multiprocessing module. It supports the exact same operations, but extends it, so that all tensors sent through a multiprocessing.Queue

```python
import torch.multiprocessing as mp

if __name__ == '__main__':
    num_processes = 4
    processes     = []
    for rank in range(num_processes):
        p = mp.Process(target=func, args=(x))
        p.start()
        processes.append(p)
    for p in processes:
        p.join()
```

## Numba
Just-in-time (JIT) compiler for python. Works well with **loops** and **numpy**, but not with pandas

Numba also caches the functions after first use as a machine code. So after first time it will be **even faster** because it doesn‚Äôt need to compile that code again.

#### Scenarios
- **Object mode** `@jit`: Only good for checking errors with python
- **Compile mode** `@jit(nopython=True)` or also `@njit`: Good machine code performance
- **Multithreading** `@jit(nopython=True, parallel=True)`: Good if your code is parallelizable
  - Automatic multithreading of array expressions and reductions
  - Explicit multithreading of loops with `prange()`: `for i in prange(10):`
  - External multithreading with tools like concurrent.futures or Dask.
- **Vectorization SIMD** `@vectorize`
  - `@vectorize(target='cpu')`: Single-threaded CPU
  - `@vectorize(target='parallel')`: Multi-core CPU
  - `@vectorize(target='cuda')`: CUDA GPU
  
```python
from numba import jit

@jit
def function(x):
    # your loop or numerically intensive computations
    return x
    
@jit(nopython=True)
def function(a, b):
    # your loop or numerically intensive computations
    return result
    
@jit(nopython=True, parallel=True)
def function(a, b):
    # your loop or numerically intensive computations
    return result
```




<h1 align="center">GPU</h1>


## PyTorch (CUDA)
```python
import torch

print("GPU available:", torch.cuda.is_available())
print("GPU name:     ", torch.cuda.get_device_name(0))
```

#### Usage
```python
tensor = torch.FloatTensor([1., 2.]).cuda()
tensor = tensor.operations ...
result = tensor.cpu()
```

#### Memory management
```python
torch.cuda.memory_allocated() # Memory usage by tensors
torch.cuda.memory_cached()    # Cache memory (visible in nvidia-smi)
torch.cuda.empty_cache()      # Free cache memory
```

## CuPy
```python
import cupy as cp
```

## Resources

- [Speed Up Your Algorithms](https://github.com/PuneetGrov3r/MediumPosts/tree/master/SpeedUpYourAlgorithms)
- [Multiprocessing vs. Threading in Python](https://sumit-ghosh.com/articles/multiprocessing-vs-threading-python-data-science)
- [Python `@delegates()`](https://www.fast.ai/2019/08/06/delegation/)
- [Python Tips and Trick, You Haven't Already Seen, Part 1](https://martinheinz.dev/blog/1)
- [Python Tips and Trick, You Haven't Already Seen, Part 2](https://martinheinz.dev/blog/4)
